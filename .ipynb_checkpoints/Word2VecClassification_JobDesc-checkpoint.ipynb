{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7b2e1364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs, gensim, logging, string, re, operator, pdb\n",
    "from scipy import spatial\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import csv\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "word2vec_model = None\n",
    "job_description = None\n",
    "word2vec_file = './data/googlenews.bin.gz'\n",
    "occupation_file = './data/OccupationData.tsv'\n",
    "regex = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "edcc0fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(str):\n",
    "    return regex.sub(' ', str)\n",
    "\n",
    "def load_word2vec(fname):\n",
    "    ''' load a pre-trained binary format word2vec into a dictionary\n",
    "    the model is downloaded from https://docs.google.com/uc?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM&export=download'''\n",
    "    word2vec = gensim.models.KeyedVectors.load_word2vec_format(fname, binary=True)\n",
    "    return word2vec\n",
    "\n",
    "def load_jobs(fname):\n",
    "    ''' read ONET occupational dataset from tab delimited text file downloaded from\n",
    "    https://www.onetcenter.org/dl_files/database/db_21_0_text/Occupation%20Data.txt'''\n",
    "    \n",
    "    jobtitle_jobdescription = {}\n",
    "    with codecs.open(fname, 'r', encoding='utf-8') as fin:\n",
    "        for line in fin:\n",
    "            fields = line.strip().split('\\t')\n",
    "            if len(fields) != 3:\n",
    "                continue\n",
    "            job_code = fields[0]\n",
    "            job_title = remove_punctuation(fields[1].lower())\n",
    "            _job_description = remove_punctuation(fields[2].lower())\n",
    "            jobtitle_jobdescription[job_title] = _job_description\n",
    "    return jobtitle_jobdescription\n",
    "\n",
    "def idtext2vec(id_text, word2vec_model):\n",
    "    '''convert a dictionary of id:text to text_id:vector by averaging the word vectors'''\n",
    "    id_vec = {}\n",
    "    for id, text in id_text.items():\n",
    "        vec = text2vec(text, word2vec_model)\n",
    "        id_vec[id] = vec\n",
    "    return id_vec\n",
    "\n",
    "def text2vec(text, word2vec_model):\n",
    "    '''convert a text to a vector by averaging the word vectors'''\n",
    "    text = text.lower()\n",
    "    words = text.split()\n",
    "    vec = 0\n",
    "    num_words = 0\n",
    "    for word in words:\n",
    "        if word in word2vec_model:\n",
    "            num_words += 1\n",
    "            vec += word2vec_model[word]\n",
    "    if num_words == 0:\n",
    "        vec = np.asarray([0] * 300)\n",
    "    else:\n",
    "        vec = vec / num_words\n",
    "    return vec\n",
    "\n",
    "def textsimilarity(text_pairs, word2vec_model):\n",
    "    text_similarity_features = []\n",
    "    for text_pair in text_pairs:\n",
    "        text1, text2 = text_pair\n",
    "        vec1 = text2vec(text1, word2vec_model)\n",
    "        vec2 = text2vec(text2, word2vec_model)\n",
    "        similarity = 1 - spatial.distance.cosine(vec1, vec2)\n",
    "        text_similarity_features.append(similarity)\n",
    "    features = np.asarray(text_similarity_features).reshape(len(text_similarity_features), 1)\n",
    "    return features\n",
    "        \n",
    "\n",
    "def sort_dic_by_value(dic):\n",
    "    sorted_x = sorted(dic.items(), key=operator.itemgetter(1))\n",
    "    return OrderedDict(sorted_x)\n",
    "\n",
    "def get_job_dict_ordered(id_text1, id_text2, word2vec_model):\n",
    "    id_vec1 = idtext2vec(id_text1, word2vec_model)\n",
    "    id_vec2 = idtext2vec(id_text2, word2vec_model)\n",
    "    id1_id2distances = {}\n",
    "    for id1, vec1 in id_vec1.items():\n",
    "        id2_distances = {}\n",
    "        for id2, vec2 in id_vec2.items():\n",
    "            distance = spatial.distance.cosine(vec1, vec2)\n",
    "            id2_distances[id2] = distance\n",
    "        id1_id2distances[id1] = sort_dic_by_value(id2_distances)\n",
    "    return id1_id2distances\n",
    "\n",
    "\n",
    "def get_features(text_pairs, jobtitle_jobdesc, word2vec_model):\n",
    "    '''given a list of text pairs as [('t11', 't12'), ('t21', 't22')....]\n",
    "    returns features, a vector where the first element is the job similarity of 't11', 't12'.\n",
    "    The length of the features vector equals the length of the pairs.'''\n",
    "    jobtitle_vec = idtext2vec(jobtitle_jobdesc, word2vec_model)\n",
    "    jobtitles = sorted(set(jobtitle_vec.keys()))\n",
    "    features = []\n",
    "    for text_pair in text_pairs:\n",
    "        text1, text2 = text_pair\n",
    "        vec1 = text2vec(text1, word2vec_model)\n",
    "        vec2 = text2vec(text2, word2vec_model)\n",
    "        vec1distances = []\n",
    "        vec2distances = []\n",
    "        for jobtitle in jobtitles:\n",
    "            vec = jobtitle_vec[jobtitle]\n",
    "            distance1 = spatial.distance.cosine(vec1, vec)\n",
    "            distance2 = spatial.distance.cosine(vec2, vec)\n",
    "            vec1distances.append(distance1)\n",
    "            vec2distances.append(distance2)\n",
    "        jobsim = 1 - spatial.distance.cosine(vec1distances, vec2distances)\n",
    "        features.append(jobsim)\n",
    "    features = np.asarray(features).reshape(len(features), 1)\n",
    "    return features\n",
    "\n",
    "def normalize_features(train_features, test_features):\n",
    "    ''' scale the feature values '''\n",
    "    #scaler = preprocessing.StandardScaler()\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    scaler.fit(train_features)\n",
    "    normal_train = scaler.transform(train_features)\n",
    "    test_features = scaler.transform(test_features)\n",
    "    return train_features, test_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "91c1d9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def import_train_test_data(train_file, test_file):\n",
    "#     html_dir = './data/html_clean/'\n",
    "    train_pairs = {}\n",
    "    test_pairs = {}\n",
    "\n",
    "    # Load train file\n",
    "    with open(train_file, 'r') as fin:\n",
    "        reader = csv.reader(fin, delimiter=',', quotechar='\"')\n",
    "        header = True\n",
    "        for row in reader:\n",
    "            if header:\n",
    "                header = False\n",
    "                continue\n",
    "\n",
    "            pair_id = int(row[0])\n",
    "            title1 = row[2]\n",
    "            title2 = row[5]\n",
    "            text1 = row[3]\n",
    "            text2 = row[6]\n",
    "            train_pairs[pair_id] = (title1 + ' ' + text1 , title2 + ' ' + text2)\n",
    "\n",
    "    # Load test file\n",
    "    with open(test_file, 'r') as fin:\n",
    "        reader = csv.reader(fin, delimiter=',', quotechar='\"')\n",
    "        header = True\n",
    "        for row in reader:\n",
    "            if header:\n",
    "                header = False\n",
    "                continue\n",
    "\n",
    "            pair_id = int(row[0])\n",
    "            title1 = row[2]\n",
    "            title2 = row[5]\n",
    "            text1 = row[3]\n",
    "            text2 = row[6]\n",
    "            test_pairs[pair_id] = (title1 + ' ' + text1 , title2 + ' ' + text2)\n",
    "    return train_pairs, test_pairs        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "805d297b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanity_check(word2vec_model, job_description):\n",
    "    #just for sanity check\n",
    "    text_job_distances = get_job_dict_ordered({1:'i am a computer programmer'}, job_description, word2vec_model)\n",
    "    print(text_job_distances[1].keys()[0:30])    \n",
    "\n",
    "def write_features(feature_file, features):\n",
    "    np.savetxt(feature_file, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b1cbdf62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-15 11:37:31,821 : INFO : loading train and test search results...\n",
      "2023-03-15 11:37:31,824 : INFO : loading job descriptions...\n",
      "2023-03-15 11:37:31,834 : INFO : loading word2vec model (takes a while)...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "type object 'Word2Vec' has no attribute 'load_word2vec_format'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[114], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m job_description \u001b[38;5;241m=\u001b[39m {job:job \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m desc \u001b[38;5;28;01mfor\u001b[39;00m job, desc \u001b[38;5;129;01min\u001b[39;00m job_description\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m      8\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloading word2vec model (takes a while)...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m word2vec_model \u001b[38;5;241m=\u001b[39m \u001b[43mload_word2vec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mword2vec_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m train_features_job \u001b[38;5;241m=\u001b[39m get_features(text_pairs\u001b[38;5;241m=\u001b[39m[train_pairs[\u001b[38;5;28mid\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mid\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(train_pairs\u001b[38;5;241m.\u001b[39mkeys())], jobtitle_jobdesc\u001b[38;5;241m=\u001b[39mjob_description, word2vec_model\u001b[38;5;241m=\u001b[39mword2vec_model) \n\u001b[1;32m     11\u001b[0m test_features_job \u001b[38;5;241m=\u001b[39m get_features(text_pairs\u001b[38;5;241m=\u001b[39m[test_pairs[\u001b[38;5;28mid\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mid\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(test_pairs\u001b[38;5;241m.\u001b[39mkeys())], jobtitle_jobdesc\u001b[38;5;241m=\u001b[39mjob_description, word2vec_model\u001b[38;5;241m=\u001b[39mword2vec_model)\n",
      "Cell \u001b[0;32mIn[111], line 7\u001b[0m, in \u001b[0;36mload_word2vec\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_word2vec\u001b[39m(fname):\n\u001b[1;32m      5\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m''' load a pre-trained binary format word2vec into a dictionary\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124;03m    the model is downloaded from https://docs.google.com/uc?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM&export=download'''\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     word2vec \u001b[38;5;241m=\u001b[39m \u001b[43mgensim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword2vec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWord2Vec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_word2vec_format\u001b[49m(fname, binary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m word2vec\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'Word2Vec' has no attribute 'load_word2vec_format'"
     ]
    }
   ],
   "source": [
    "   \n",
    "if __name__ == '__main__':\n",
    "    logging.info('loading train and test search results...')\n",
    "    train_pairs, test_pairs = import_train_test_data(train_file='./data/alta16_kbcoref_train_search_results.csv', test_file='./data/alta16_kbcoref_test_search_results.csv')\n",
    "    logging.info('loading job descriptions...')\n",
    "    job_description = load_jobs(fname=occupation_file)\n",
    "    #add job title to job description\n",
    "    job_description = {job:job + ' ' + desc for job, desc in job_description.items()}\n",
    "    logging.info('loading word2vec model (takes a while)...')\n",
    "    word2vec_model = load_word2vec(fname=word2vec_file)\n",
    "    train_features_job = get_features(text_pairs=[train_pairs[id] for id in sorted(train_pairs.keys())], jobtitle_jobdesc=job_description, word2vec_model=word2vec_model) \n",
    "    test_features_job = get_features(text_pairs=[test_pairs[id] for id in sorted(test_pairs.keys())], jobtitle_jobdesc=job_description, word2vec_model=word2vec_model)\n",
    "    train_features_txtsim = textsimilarity(text_pairs=[train_pairs[id] for id in sorted(train_pairs.keys())], word2vec_model=word2vec_model)\n",
    "    test_features_txtsim = textsimilarity(text_pairs=[test_pairs[id] for id in sorted(test_pairs.keys())], word2vec_model=word2vec_model)\n",
    "    train_features = np.hstack((train_features_job, train_features_txtsim))\n",
    "    test_features = np.hstack((test_features_job, test_features_txtsim))\n",
    "    #train_features = preprocessing.scale(train_features)\n",
    "    #test_features = preprocessing.scale(test_features)\n",
    "    #train_features, test_features = normalize_features(train_features=train_features, test_features=test_features)\n",
    "    features = np.vstack((train_features, test_features))\n",
    "    np.savetxt('./data/features.txt', features)\n",
    "    pdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6363e56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543cfa89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
